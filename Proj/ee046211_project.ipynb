{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzV9wsJ5pGhf"
      },
      "source": [
        "# <img src=\"https://img.icons8.com/bubbles/50/000000/mind-map.png\" style=\"height:50px;display:inline\"> EE 046211 - Technion - Deep Learning\n",
        "---\n",
        "\n",
        "## Course Project - Actually good trash statistics\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZZybn3NpGhh"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/information.png\" style=\"height:50px;display:inline\"> Students Information\n",
        "---\n",
        "\n",
        "|Name     |Campus Email| ID  |\n",
        "|---------|--------------------------------|----------|\n",
        "|Alexander Balabanov| alexander.b@campus.technion.ac.il| 312775364|\n",
        "|Dr. John Zoidberg| (\\\\\\/)(;,,;)(\\\\\\/)@campus.technion.ac.il| 3000|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9uxrDgJ9u_q"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Get Datasets\n",
        "---\n",
        "The project will include 2 dataset that we are going to work with:\n",
        "- [COCO](https://cocodataset.org/#home), dataset of everyday images with 330k images and 80 catagories. The data is the segmantation of the objects.\n",
        "- [TACO](http://tacodataset.org/), data of trash in nature"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "inq_9VTSrvb_",
        "outputId": "ecb3580f-3a44-4e56-f02b-7f68f4d73011",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/EEDL_046211/\n",
        "!git clone https://github.com/pedropro/TACO\n",
        "!git pull\n",
        "%cd ./TACO\n",
        "%ls -l"
      ],
      "metadata": {
        "id": "cIuh9PUXvrwL",
        "outputId": "37141f2a-a39b-49fd-cbe7-3071e8626b84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/EEDL_046211\n",
            "fatal: destination path 'TACO' already exists and is not an empty directory.\n",
            "fatal: not a git repository (or any parent up to mount point /content)\n",
            "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
            "/content/gdrive/MyDrive/EEDL_046211/TACO\n",
            "total 18421\n",
            "drwx------ 2 root root     4096 Jan 11 15:30 \u001b[0m\u001b[01;34mdata\u001b[0m/\n",
            "-rw------- 1 root root 18845855 Jan 11 15:30 demo.ipynb\n",
            "drwx------ 3 root root     4096 Jan 11 15:30 \u001b[01;34mdetector\u001b[0m/\n",
            "-rw------- 1 root root     1751 Jan 11 15:30 download.py\n",
            "-rw------- 1 root root     1074 Jan 11 15:30 LICENSE\n",
            "-rw------- 1 root root     4475 Jan 11 15:30 README.md\n",
            "-rw------- 1 root root       71 Jan 11 15:30 requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 download.py"
      ],
      "metadata": {
        "id": "scgwwxlPw4UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../\n",
        "%pwd"
      ],
      "metadata": {
        "id": "8Mxtxh6CQWUJ",
        "outputId": "bf31c89f-bc16-4b98-8d52-42fe9c98309e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/EEDL_046211\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/EEDL_046211'"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna"
      ],
      "metadata": {
        "id": "YUn2OHftHly9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "scnIyi7W9u_r"
      },
      "outputs": [],
      "source": [
        "# imports for the tutorial\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import time\n",
        "import os\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "\n",
        "# optuna\n",
        "import optuna\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TACO_DataSet(Dataset):\n",
        "  def __init__(self, img_dir, transform=None, target_transform=None):\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "  \n",
        "  def __len__(self):\n",
        "    return 0\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    image = []\n",
        "    bbox = []\n",
        "\n",
        "    return image, bbox"
      ],
      "metadata": {
        "id": "349RG6yg2mVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GIoU(nn.Module):\n",
        "  def __init__(self):\n",
        "    self.eq = 0\n",
        "\n",
        "  def forward(pred, gt):\n",
        "    return 0\n",
        "\n",
        "\n",
        "def stepLrSch(opt):\n",
        "  return torch.optim.lr_scheduler.StepLR(opt, 2, gamma=0.9)\n",
        "\n",
        "\n",
        "def default_transform():\n",
        "  return transforms.Compose([\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])"
      ],
      "metadata": {
        "id": "EzZgKJxf4WO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HP():\n",
        "  def __init__(self, epochs=16, btz=128, lr=1e-3, opt=None, crit=None, sch=None, bt_tr=None):\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = btz\n",
        "    self.lr = lr\n",
        "    self.optimizer = opt if opt is not None else torch.optim.Adam\n",
        "    self.criterion = crit if crit is not None else GIou()\n",
        "    self.scheduler = sch if sch is not None else stepLrSch\n",
        "    self.bt_transform = bt_tr if bt_tr is not None else default_transform()\n",
        "  \n",
        "  def get_optimizer(model):\n",
        "    self.optimizer = self.optimizer(model.parameters(), lr=self.lr)\n",
        "    return self.optimizer\n",
        "\n",
        "  def get_criterion():\n",
        "    return self.criterion\n",
        "\n",
        "  def get_scheduler():\n",
        "    self.scheduler = self.scheduler(self.optimizer)\n",
        "    return self.scheduler\n"
      ],
      "metadata": {
        "id": "ZdScZcNv-rKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TACO_model(nn.Module):\n",
        "  def __init__(self, classes=25, freeze=1)):\n",
        "    super(TACO_model, self).__init__()\n",
        "    self.yolo = torch.hub.load('ultralytics/yolo5', 'yolo5s', pretraind=True, classes=classes)\n",
        "    for m in [m_ for m_ in self.yolo.modules()][:-freeze]:\n",
        "      m.requires_grad_(False)\n",
        "\n",
        "  def forward(self, imgs):\n",
        "    return self.yolo(imgs)\n"
      ],
      "metadata": {
        "id": "XlVyLpvF519E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DL_model():\n",
        "  def __init__(self, hp=None):\n",
        "    self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    self.model = TACO_model().to(self.device)\n",
        "    self.hp = hp if hp is not None else HP()\n",
        "    self.optimizer = hp.get_optimizer(self.model)\n",
        "    self.criterion = hp.get_criterion()\n",
        "    self.scheduler = hp.get_scheduler()\n",
        "    #self.epochs = hyper_par.get_epoch() "
      ],
      "metadata": {
        "id": "uaHc3i8s0rgN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = []\n",
        "g = []\n",
        "for m in [m_ for m_ in model.modules()][:-1]:\n",
        "  l.append(m)\n",
        "  m.requires_grad_(False)\n",
        "for p in model.parameters():\n",
        "  if p.requires_grad:\n",
        "    g.append(p)\n",
        "print(len(l))\n",
        "print(len(g))"
      ],
      "metadata": {
        "id": "8ElytPmoTrOS",
        "outputId": "e831592c-17f6-46f8-c6e5-0c3a05957606",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "270\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjAiMX1l9u_s"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n",
        "---\n",
        "* Icons made by <a href=\"https://www.flaticon.com/authors/becris\" title=\"Becris\">Becris</a> from <a href=\"https://www.flaticon.com/\" title=\"Flaticon\">www.flaticon.com</a>\n",
        "* Icons from <a href=\"https://icons8.com/\">Icons8.com</a> - https://icons8.com\n",
        "* Datasets from <a href=\"https://www.kaggle.com/\">Kaggle</a> - https://www.kaggle.com/"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "ee046211_project.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}