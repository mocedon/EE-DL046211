{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzV9wsJ5pGhf"
      },
      "source": [
        "# <img src=\"https://img.icons8.com/bubbles/50/000000/mind-map.png\" style=\"height:50px;display:inline\"> EE 046211 - Technion - Deep Learning\n",
        "---\n",
        "\n",
        "## HW3 - Sequential Tasks and Training Methods\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq2c8X93pGhh"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/clouds/96/000000/keyboard.png\" style=\"height:50px;display:inline\"> Keyboard Shortcuts\n",
        "---\n",
        "* Run current cell: **Ctrl + Enter**\n",
        "* Run current cell and move to the next: **Shift + Enter**\n",
        "* Show lines in a code cell: **Esc + L**\n",
        "* View function documentation: **Shift + Tab** inside the parenthesis or `help(name_of_module)`\n",
        "* New cell below: **Esc + B**\n",
        "* Delete cell: **Esc + D, D** (two D's)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZZybn3NpGhh"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/information.png\" style=\"height:50px;display:inline\"> Students Information\n",
        "---\n",
        "* Fill in\n",
        "\n",
        "|Name     |Campus Email| ID  |\n",
        "|---------|--------------------------------|----------|\n",
        "|Alexander Balabanov| alexander.b@campus.technion.ac.il| 312775364|\n",
        "|| (\\\\\\/)(;,,;)(\\\\\\/)| |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDK5zqhdpGhi"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/upload-to-cloud.png\" style=\"height:50px;display:inline\"> Submission Guidelines\n",
        "---\n",
        "* Maximal garde: 100.\n",
        "* Submission only in **pairs**. \n",
        "    * Please make sure you have registered your group in Moodle (there is a group creation component on the Moodle where you need to create your group and assign members).\n",
        "* **No handwritten submissions.** You can choose whether to answer in a Markdown cell in this notebook or attach a PDF with your answers.\n",
        "* <a style='color:red'> SAVE THE NOTEBOOKS WITH THE OUTPUT, CODE CELLS THAT WERE NOT RUN WILL NOT GET ANY POINTS! </a>\n",
        "* What you have to submit:\n",
        "    * If you have answered the questions in the notebook, you should submit this file only, with the name: `ee046211_hw3_id1_id2.ipynb`.\n",
        "    * If you answered the questionss in a different file you should submit a `.zip` file with the name `ee046211_hw3_id1_id2.zip` with content:\n",
        "        * `ee046211_hw3_id1_id2.ipynb` - the code tasks\n",
        "        * `ee046211_hw3_id1_id2.pdf` - answers to questions.\n",
        "    * No other file-types (`.py`, `.docx`...) will be accepted.\n",
        "* Submission on the course website (Moodle).\n",
        "* **Latex in Colab** - in some cases, Latex equations may no be rendered. To avoid this, make sure to not use *bullets* in your answers (\"* some text here with Latex equations\" -> \"some text here with Latex equations\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmSj_UufpGhi"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/dusk/64/000000/online.png\" style=\"height:50px;display:inline\"> Working Online and Locally\n",
        "---\n",
        "* You can choose your working environment:\n",
        "    1. `Jupyter Notebook`, **locally** with <a href=\"https://www.anaconda.com/distribution/\">Anaconda</a> or **online** on <a href=\"https://colab.research.google.com/\">Google Colab</a>\n",
        "        * Colab also supports running code on GPU, so if you don't have one, Colab is the way to go. To enable GPU on Colab, in the menu: `Runtime`$\\rightarrow$ `Change Runtime Type` $\\rightarrow$`GPU`.\n",
        "    2. Python IDE such as <a href=\"https://www.jetbrains.com/pycharm/\">PyCharm</a> or <a href=\"https://code.visualstudio.com/\">Visual Studio Code</a>.\n",
        "        * Both allow editing and running Jupyter Notebooks.\n",
        "\n",
        "* Please refer to `Setting Up the Working Environment.pdf` on the Moodle or our GitHub (https://github.com/taldatech/ee046211-deep-learning) to help you get everything installed.\n",
        "* If you need any technical assistance, please go to our Piazza forum (`hw3` folder) and describe your problem (preferably with images)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlp1Fp4ppGhj"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/bubbles/50/000000/checklist.png\" style=\"height:50px;display:inline\"> Agenda\n",
        "---\n",
        "\n",
        "* [Part 1 - Theory](#-Part-1---Theory)\n",
        "    * [Q1 - Deep NLP Case Study](#-Question-1--Deep-NLP-Case-Study)\n",
        "    * [Q2 -Layer Normalization](#-Question-2--Layer-Normalization)\n",
        "    * [Q3 - Batch Normalization](#-Question-3--Batch-Normalization)\n",
        "* [Part 2 - Code Assignments - Sequence-to-Sequence with Transformers](#-Part-2---Code-Assignments)\n",
        "    * [Task 1 - Task 1 - Loading and Observing the Data](#-Task-1----Loading-and-Observing-the-Data)\n",
        "    * [Task 2 - Preparing the Data - Separating to Inputs and Targets](#-Task-2----Preparing-the--Data---Separating-to-Inputs-and-Targets)\n",
        "    * [Task 3 - Define Hyperparameters and Initialize the Model](#-Task-3----Define-Hyperparameters-and-Initialize-the-Model)\n",
        "    * [Task 4 - Train and Evaluate the Language Model](#-Task-4----Train-and-Evaluate-the-Language-Model)\n",
        "    * [Task 5 - Generate Sentences](#-Task-5----Generate-Sentences)\n",
        "* [Credits](#-Credits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKtSiQX_pGhj"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/cute-clipart/64/000000/ball-point-pen.png\" style=\"height:50px;display:inline\"> Part 1 - Theory\n",
        "---\n",
        "* You can choose whether to answser these straight in the notebook (Markdown + Latex) or use another editor (Word, LyX, Latex, Overleaf...) and submit an additional PDF file, **but no handwritten submissions**.\n",
        "* You can attach additional figures (drawings, graphs,...) in a separate PDF file, just make sure to refer to them in your answers.\n",
        "\n",
        "* $\\large\\LaTeX$ <a href=\"https://kapeli.com/cheat_sheets/LaTeX_Math_Symbols.docset/Contents/Resources/Documents/index\">Cheat-Sheet</a> (to write equations)\n",
        "    * <a href=\"http://tug.ctan.org/info/latex-refsheet/LaTeX_RefSheet.pdf\">Another Cheat-Sheet</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsqSFZG1pGhj"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 1 -Deep NLP Case Study\n",
        "---\n",
        "* You are consulting for a healthcare company. They provide you with clinical notes of the first encounter that each patient had with their doctor regarding a particular medical episode.\n",
        "* There are a total of 12 million patients and clinical notes. At the time that each clinical note was written, the underlying illnesses associated with the medical episode were unknown to the doctor. \n",
        "* The company provides you with the true set of illnesses associated with each medical episode and asks you to build a model that can infer these underlying illnesses using only the current clinical note and all previous clinical notes belonging to the patient.\n",
        "* The set of notes provided to you span 10 years; each patient therefore can have multiple clinical notes (medical episodes) in that period.\n",
        "* You also have a vector representation of each patient note (note-vector) which was built using a summation of the word vectors of the note.\n",
        "\n",
        "\n",
        "1. You assume that a patient’s past medical history is informative of their current illness. As such, you apply a recurrent neural network to predict the current illness based on the patient’s current and previous note-vectors. Explain why a recurrent neural network would yield better results than a feed-forward network in which your input is the summation of past and current note-vectors?\n",
        "\n",
        "2. A patient may have any number of illnesses from a list of 70,000 known medical illnesses. The output of your recurrent neural network will therefore be a vector with 70,000 elements. Each element in this output vector represents the probability that the patient has the illness that maps to that particular element. Illnesses are not mutually exclusive i.e. having one illness does not preclude you from having any other illnesses. Given this insight, is it better to have a sigmoid non-linearity or a softmax non-linearity as your output unit? Why?\n",
        "\n",
        "3. You try to figure out a better way to reduce the training and testing time of your model. You perform a run time analysis and observe that the computational bottleneck is in your output unit: the number of target illnesses is too high. Each illness in the list of 70,000 illnesses belongs to one of 300 classes (e.g. a migraine belongs to the neurological disorder class). He shares with you a dictionary which maps each illness to its corresponding class. How can you use this information to reduce the **time** complexity of your model?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Q1\n",
        "\n",
        "* S1 -\n",
        "\n",
        "  Medical history is usually inportant for diagnosys. therfore it is important to take it In account.\n",
        "\n",
        "  A feed forward network can that into account the history and current situation.\n",
        "But it doesn't have a clear compartmentalization to notes and paerts of notes can get mixed and the current note has a equal weight to all others that also can hinder performance.\n",
        "\n",
        "  The difference bewteen RNN and a concatenated (or sumed) history and current notes is the build in connection for 1 note to the other, it has a clear structure to incoporate the processed note with all history before in steps.\n",
        "The current note has a higher weight to it since all history is summed to a single vector.\n",
        "\n",
        "  Another factor is the number of parameters, long history requires huge tensors in the feed forward net compared to RNN which give the RNN better change to converge.\n",
        "\n",
        "* S2 - \n",
        "\n",
        "  Both sigmoid and softmax takes the output and constraints it to a range of [0-1], the differnce is that the sum on the vector of 70,000 nodes equals to 1 in case of softmax and sigmoid doesn't have any constraints.\n",
        "\n",
        "  Since medical conditions aren't mutually exclucsive, and the sad really is that one illness corrolate strongly with others and lead to others e.g. Wilson's cause liver cirrhosis (a gold isn't that precious now, isn't it). One doesn't want to see the liver cirrhosis which is easier to diagnose decrease the value of the wilson's node since it is the underlying problem.\n",
        "\n",
        "  Ilness vector has huge relevancy and how generaly healthy a patient is can be calculated by the invrese L1 norm.\n",
        "  A usually healthy patient shouldn't has the same output vector by change with a sick one only because the vector is normalized.\n",
        "\n",
        "  For those 2 main reasons is it clear that a signoid is the right choice for the network.\n",
        "\n",
        "* S3 -\n",
        "\n",
        "  Changing the ilness vector from 70,000 nodes to 300 we change the marticies ot the output vector and from it to the next iteration. that means for a run of K iterations we recduce computation by $K\\cdot(70000^2-300^2)≈K\\cdot4.9\\times10^9$ floating point iterations. Not includiong other architecture changes we can do to accomodate the vector reduction (previous and latter layers can be also smaller).\n",
        "\n"
      ],
      "metadata": {
        "id": "mBBJ0gtejFn1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC0H7D7eJebT"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 2 -Layer Normalization\n",
        "---\n",
        "\n",
        "1. When does Group Normalization is equivalent to Instance Normalization?\n",
        "2. When does Group Normalization is equivalent to Layer Normalization?\n",
        "3. For the following batch of $N=3$ 2D images with $C=3$ channels each, what is the output of:\n",
        "    * Batch Normalization\n",
        "    * Layer Normalization\n",
        "    * Instance Normalization\n",
        "\n",
        "\n",
        "* Use only the *mean* for the calculation, no need for the std (assume there are no learnable parameters).\n",
        "    \n",
        "$$ n=1: \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}, \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}, \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix} $$\n",
        "\n",
        "$$ n=2: \\begin{bmatrix} 0.5 & 0.5 \\\\ 0.5 & 0.5 \\end{bmatrix}, \\begin{bmatrix} 0.5 & 0 \\\\ 0.5 & 0 \\end{bmatrix}, \\begin{bmatrix} 0 & 0.5 \\\\ 0 & 0.5 \\end{bmatrix} $$\n",
        "\n",
        "$$ n=3: \\begin{bmatrix} 1 & 1 \\\\ 1 & 0.5 \\end{bmatrix}, \\begin{bmatrix} 0.5 & 1 \\\\ 0.5 & 1 \\end{bmatrix}, \\begin{bmatrix} 1 & 0.5 \\\\ 1 & 1 \\end{bmatrix} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Q2\n",
        "\n",
        "Assuming we talk about a tensor of $[N\\times C\\times W\\times H]$, and group norm is sized $[1\\times G\\times W\\times H]$\n",
        "\n",
        "* S1 -\n",
        "\n",
        "  Group Normalization is equivilant to Instance Norm. if the number of channels is 1 (C=1) or the group size is defined as one(G=1).\n",
        "\n",
        "* S2 -\n",
        "\n",
        "  Group Normalization is equavilant to Layer Norm. if the number of channels equals group size(G=C) \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gRLQYC4HvyPb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* S3 -\n",
        "  Batch norm:\n",
        "  $$Op = [3,1,2,2] $$\n",
        "  Finding $\\mu_1$:$$\n",
        "\\mu_1 = \\frac{1}{(3\\cdot1\\cdot2\\cdot2)} \\cdot \\left(\n",
        "\\bar1 \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}\\bar1 +\n",
        "\\bar1 \\begin{bmatrix} 0.5 & 0.5 \\\\ 0.5 & 0.5 \\end{bmatrix}\\bar1 +\n",
        "\\bar1 \\begin{bmatrix} 1 & 1 \\\\ 1 & 0.5 \\end{bmatrix}\\bar1\n",
        "\\right)\n",
        "  $$\n",
        "  Resulting:\n",
        "  $$\n",
        "  \\mu_1 =\\frac{2+1+3.5}{12}=\\frac{13}{24}\n",
        "  $$\n",
        "  Finding $\\mu_2$:$$\n",
        "\\mu_2 = \\frac{1}{(3\\cdot1\\cdot2\\cdot2)} \\cdot \\left(\n",
        "  \\bar1 \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}\\bar1 +\n",
        "  \\bar1 \\begin{bmatrix} 0.5 & 0 \\\\ 0.5 & 0 \\end{bmatrix}\\bar1 +\n",
        "  \\bar1 \\begin{bmatrix} 0.5 & 1 \\\\ 0.5 & 1 \\end{bmatrix}\\bar1 \n",
        "  \\right)\n",
        "  $$\n",
        "  Resulting:\n",
        "  $$\n",
        "  \\mu_2=\\frac{2+1+3}{12}=\\frac{1}{2}\n",
        "  $$\n",
        "  Finding $\\mu_3$:\n",
        "  $$\n",
        "\\mu_3 = \\frac{1}{(3\\cdot1\\cdot2\\cdot2)} \\cdot \\left(\n",
        "  \\bar1 \\begin{bmatrix} 1 & 1 \\\\ 1 & 0.5 \\end{bmatrix}\\bar1 +\n",
        "  \\bar1 \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}\\bar1 +\n",
        "  \\bar1 \\begin{bmatrix} 1 & 0.5 \\\\ 1 & 1 \\end{bmatrix}\\bar1 \n",
        "  \\right)\n",
        "  $$\n",
        "Resulting:\n",
        "$$\n",
        "\\mu_3 = \\frac{4+1+3.5}{12}=\\frac{17}{24}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "4nhgaDOi3xkj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  * S3 - Layer norm:\n",
        "  $$Op = [1,3,2,2] $$\n",
        "  Finding $\\mu_1$:$$\n",
        "\\mu_1 = \\frac{1}{(3\\cdot1\\cdot2\\cdot2)} \\cdot \\left(\n",
        "\\bar1 \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}\\bar1 +\n",
        "\\bar1 \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}\\bar1 +\n",
        "\\bar1 \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}\\bar1\n",
        "\\right)\n",
        "  $$\n",
        "  Resulting:\n",
        "  $$\n",
        "  \\mu_1 =\\frac{2+2+4}{12}=\\frac{2}{3}\n",
        "  $$\n",
        "  Finding $\\mu_2$:$$\n",
        "\\mu_2 = \\frac{1}{(3\\cdot1\\cdot2\\cdot2)} \\cdot \\left(\n",
        "  \\bar1 \\begin{bmatrix} 0.5 & 0.5 \\\\ 0.5 & 0.5 \\end{bmatrix}\\bar1 +\n",
        "  \\bar1 \\begin{bmatrix} 0.5 & 0 \\\\ 0.5 & 0 \\end{bmatrix}\\bar1 +\n",
        "  \\bar1 \\begin{bmatrix} 0 & 0.5 \\\\ 0 & 0.5 \\end{bmatrix}\\bar1 \n",
        "  \\right)\n",
        "  $$\n",
        "  Resulting:\n",
        "  $$\n",
        "  \\mu_2=\\frac{2+1+1}{12}=\\frac{1}{3}\n",
        "  $$\n",
        "  Finding $\\mu_3$:\n",
        "  $$\n",
        "\\mu_3 = \\frac{1}{(3\\cdot1\\cdot2\\cdot2)} \\cdot \\left(\n",
        "  \\bar1 \\begin{bmatrix} 1 & 1 \\\\ 1 & 0.5 \\end{bmatrix}\\bar1 +\n",
        "  \\bar1 \\begin{bmatrix} 0.5 & 1 \\\\ 0.5 & 1 \\end{bmatrix}\\bar1 +\n",
        "  \\bar1 \\begin{bmatrix} 1 & 0.5 \\\\ 1 & 1 \\end{bmatrix}\\bar1 \n",
        "  \\right)\n",
        "  $$\n",
        "Resulting:\n",
        "$$\n",
        "\\mu_3 = \\frac{3.5+2+3.5}{12}=\\frac{3}{4}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "HfQlVMa_3v7U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  * S3 - Batch norm:\n",
        "  $$Op = [1,1,2,2] $$\n",
        "  Finding $\\mu_1$:$$\n",
        "\\mu_1 = \\frac{1}{(1\\cdot1\\cdot2\\cdot2)} \\cdot \\left(\n",
        "\\bar1 \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}\\bar1\n",
        "\\right) =\\frac{2}{4}=\\frac{1}{2}\n",
        "  $$\n",
        "  Finding $\\mu_2$:$$\n",
        "\\mu_2 = \\frac{1}{(1\\cdot1\\cdot2\\cdot2)} \\cdot \\left(\n",
        "\\bar1 \\begin{bmatrix} 0.5 & 0.5 \\\\ 0.5 & 0.5 \\end{bmatrix}\\bar1\n",
        "\\right) =\\frac{2}{4}=\\frac{1}{2}\n",
        "  $$\n",
        "  Finding $\\mu_3$:$$\n",
        "\\mu_3 = \\frac{1}{(1\\cdot1\\cdot2\\cdot2)} \\cdot \\left(\n",
        "\\bar1 \\begin{bmatrix} 1 & 1 \\\\ 1 & 0.5 \\end{bmatrix}\\bar1\n",
        "\\right) =\\frac{3.5}{4}=\\frac{7}{8}\n",
        "  $$\n",
        "\n",
        "  Finding $\\mu_4$:$$\n",
        "\\mu_4 = \\frac{1}{(1\\cdot1\\cdot2\\cdot2)} \\cdot \\left(\n",
        "  \\bar1 \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}\\bar1\n",
        "  \\right)\\frac{2}{4}=\\frac{1}{2}\n",
        "  $$\n",
        "  Finding $\\mu_5$:$$\n",
        "\\mu_5 = \\frac{1}{(1\\cdot1\\cdot2\\cdot2)} \\cdot \\left(\n",
        "  \\bar1 \\begin{bmatrix} 0.5 & 0 \\\\ 0.5 & 0 \\end{bmatrix}\\bar1 \n",
        "  \\right)\\frac{1}{4}\n",
        "  $$\n",
        "  Finding $\\mu_6$:$$\n",
        "\\mu_6 = \\frac{1}{(1\\cdot1\\cdot2\\cdot2)} \\cdot \\left(\n",
        "  \\bar1 \\begin{bmatrix} 0.5 & 1 \\\\ 0.5 & 1 \\end{bmatrix}\\bar1 \n",
        "  \\right)\\frac{3}{4}\n",
        "  $$\n",
        "  Finding $\\mu_7$:\n",
        "  $$\n",
        "\\mu_7 = \\frac{1}{(3\\cdot1\\cdot2\\cdot2)} \\cdot \\left(\n",
        "  \\bar1 \\begin{bmatrix} 1 & 1 \\\\ 1 & 1 \\end{bmatrix}\\bar1\n",
        "  \\right)= \\frac{4}{4}=1\n",
        "  $$\n",
        "  Finding $\\mu_8$:\n",
        "  $$\n",
        "\\mu_8 = \\frac{1}{(3\\cdot1\\cdot2\\cdot2)} \\cdot \\left(\n",
        "  \\bar1 \\begin{bmatrix} 0 & 0.5 \\\\ 0 & 0.5 \\end{bmatrix}\\bar1\n",
        "  \\right)= \\frac{1}{4}\n",
        "  $$\n",
        "  Finding $\\mu_9$:\n",
        "  $$\n",
        "\\mu_9 = \\frac{1}{(3\\cdot1\\cdot2\\cdot2)} \\cdot \\left(\n",
        "  \\bar1 \\begin{bmatrix} 1 & 0.5 \\\\ 1 & 1 \\end{bmatrix}\\bar1 \n",
        "  \\right)= \\frac{3.5}{4}=\\frac{7}{8}\n",
        "  $$\n",
        "\n"
      ],
      "metadata": {
        "id": "F0ZF0O0s3za_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_Gp2fe5JebU"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/clouds/100/000000/question-mark.png\" style=\"height:50px;display:inline\"> Question 3 -Batch Normalization\n",
        "---\n",
        "This question relates to lectures 8-9 (from slide 9):\n",
        "\n",
        "Prove that **without** regularization, BatchNorm **scale invariance** for parameters $\\mathbf{w}$ implies:\n",
        "1. $\\nabla \\mathcal{L}(\\mathbf{w})^T\\mathbf{w} = 0$\n",
        "2. And under gradient flow dynamics ($\\dot{\\mathbf{w}} = -\\eta \\nabla \\mathcal{L}(\\mathbf{w})$) this implies (L2) norm conservation: $\\forall t: ||\\mathbf{w}(t)||^2 = C$\n",
        "\n",
        "Hint: see results from the multilayer networks lecture."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer 3\n",
        " * S1\n",
        "\n",
        "  First we show that batch norm (BN) is scale invariant.\n",
        "  $$\n",
        "BN(aw)=\\frac{aw-\\mu_{aw}}{\\sqrt{\\sigma_{aw}}}=\\frac{aw-a\\mu_{w}}{\\sqrt{a^2\\sigma_{w}}}=\\frac{a\\cdot(w-\\mu_{w})}{a\\sqrt{\\sigma_w}}=\\frac{(w-\\mu_{w})}{\\sqrt{\\sigma_w}}=BN(w)\n",
        "  $$$$\n",
        "\\{\\mathbb{E}[aw]=a\\mathbb{E}[w] ; var(aw) = a^2\\cdot var(w)\\}$$\n",
        "  We assume $\\epsilon=0$ since it is computational safety guard.\n",
        "  \n",
        "  Now as we saw in lecture 5\n",
        "$$\\mathcal{L}(BN(w))=\\mathcal{L}(BN(aw))\n",
        "$$\n",
        "deriving w.r to a\n",
        "$$\n",
        "0=\\frac{\\partial}{\\partial a}\\mathcal{L}(BN(aw))=\\frac{\\partial}{\\partial BN(aw)}\\mathcal{L}(BN(aw))^T\\cdot\\frac{\\partial}{\\partial aw}BN(aw)\\cdot\\frac{\\partial}{\\partial a}aw=$$$$=∇\\mathcal{L}(aw)\\cdot w\n",
        "$$\n",
        "Solving:\n",
        "\\begin{equation}\n",
        "\\begin{Bmatrix}\n",
        "\\frac{\\partial}{\\partial aw}BN(aw)=\\frac{\\partial}{\\partial aw}\\left( \\frac{aw-\\mu_{aw}}{a\\sqrt{\\sigma_w}} \\right)=\\frac{1}{a\\sqrt{\\sigma_{w}}}\n",
        "\\\\ \n",
        "\\frac{\\partial}{\\partial a}aw=w \n",
        "\\end{Bmatrix}\n",
        "\\end{equation}\n",
        "Resulting in:\n",
        "$$\n",
        "\\frac{1}{a\\sqrt{\\sigma_w}}\\cdot ∇\\mathcal{L}(BN(w))^Tw=0\n",
        "$$\n",
        "As we saw in the lecture there is translation invariance and scaling invariance and BN is a manifestation of both and therefore\n",
        "$$\n",
        "∇\\mathcal{L}(BN(w))=∇\\mathcal{L}(bw-c)=∇\\mathcal{L}(w)$$\n",
        "Getting to:\n",
        "$$∇\\mathcal{L}(w)^T\\cdot W=0 $$ \n",
        "\n",
        "* S2 \n",
        "\n",
        "  Let us use the L2 norm of w and drive over time\n",
        "  $$\n",
        "\\frac{\\partial}{\\partial t}\\cdot ||w||^2= \\dot{w}^T  w+ w^T\\dot w = -η\\nabla\\mathcal{L}(w)^T\\cdot w -w^T\\cdot η\\nabla\\mathcal{L}(w)=$$$$=-\\eta(\\nabla\\mathcal{L}(w)^T\\cdot w + (\\nabla\\mathcal{L}(w)\\cdot w)^T)=-\\eta(0+0)=0 $$\n",
        "Gradient is 0 and therefore:\n",
        "$$||w||^2=C_{onst}$$"
      ],
      "metadata": {
        "id": "f1nts4tb8iN1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D-14iM7pGhm"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/officel/80/000000/code.png\" style=\"height:50px;display:inline\"> Part 2 - Code Assignments\n",
        "---\n",
        "* You must write your code in this notebook and save it with the output of all of the code cells.\n",
        "* Additional text can be added in Markdown cells.\n",
        "* You can use any other IDE you like (PyCharm, VSCode...) to write/debug your code, but for the submission you must copy it to this notebook, run the code and save the notebook with the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpeTcq7vJebU",
        "outputId": "0e4f7886-5e25-493d-8588-bae4eb611854"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa99645cb90>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# imports for the practice (you can add more if you need)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "\n",
        "# pytorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchtext\n",
        "import torchtext.legacy.data as data\n",
        "import torchtext.legacy.datasets as datasets\n",
        "import torch.nn.functional as f\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "\n",
        "seed = 211\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6U1qWD83JebV"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/bubbles/50/000000/workflow.png\" style=\"height:50px;display:inline\">  Sequence-to-Sequence with Transformers\n",
        "---\n",
        "* In this exercise, you are going to build a language model using PyTroch's Transformer module.\n",
        "* We will work with the **Wikitext-2** dataset: the WikiText language modeling dataset is a collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia.\n",
        "* After training, you will be able to generate senetences!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDgKh7xzJebW"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 1  - Loading and Observing the Data\n",
        "---\n",
        "1. Initialize a text `data.Field` using `data.utils.get_tokenizer(\"basic_english\")`, `<sos>` and `<eos>` as start and end tokens, and consider only lower case words (`lower=True`).\n",
        "2. Load the train, valid and test *texts* using `datasets.WikiText2.splits` with your text data field from (1).\n",
        "3. Build a vocabulary using only the train data.\n",
        "4. Create the train, valid and test data using the provided `batchify` function.\n",
        "5. Use the `batchify` function with `batch_size=20` to create a data loader. Print the shape of the result.\n",
        "6. Print 2 train samples. Use the vocabulary you built to transfer between tokens to words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dZ0Ur6RSJebW"
      },
      "outputs": [],
      "source": [
        "def batchify(data, bsz, text_field):\n",
        "    data = text_field.numericalize([data.examples[0].text])\n",
        "    # Divide the dataset into bsz parts.\n",
        "    nbatch = data.size(0) // bsz\n",
        "    # Trim off any extra elements that wouldn't cleanly fit (remainders).\n",
        "    data = data.narrow(0, 0, nbatch * bsz)\n",
        "    # Evenly divide the data across the bsz batches.\n",
        "    data = data.view(bsz, -1).t().contiguous()\n",
        "    return data.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tu8LVmgoJebW"
      },
      "outputs": [],
      "source": [
        "#S1\n",
        "token = data.utils.get_tokenizer(\"basic_english\")\n",
        "text = data.Field(eos_token='<eos>', init_token='<sos>', lower=True, tokenize=token)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#S2\n",
        "datasets.WikiText2.download('./datasets')\n",
        "ds_train_, ds_valid_, ds_test_ = datasets.WikiText2.splits(text_field=text, root='./datasets',)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfmQlFxUKRWq",
        "outputId": "218d6c53-2ead-4deb-d437-1657866cb5ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading wikitext-2-v1.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.48M/4.48M [00:00<00:00, 8.79MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "extracting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#S3\n",
        "num_words = 50_000\n",
        "text.build_vocab(ds_train_, max_size=num_words)\n",
        "vocab = text.vocab"
      ],
      "metadata": {
        "id": "7KvPH4TMKREu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#S4\n",
        "ds_train = batchify(ds_train_, 20, text)\n",
        "ds_valid = batchify(ds_valid_, 20, text)\n",
        "ds_test = batchify(ds_test_, 20, text)\n",
        "#S5\n",
        "print(\"Train dataset is shaped : {}\".format(ds_train.shape))\n",
        "print(\"Validation dataset is shaped : {}\".format(ds_valid.shape))\n",
        "print(\"Test dataset is shaped : {}\".format(ds_test.shape))\n",
        "#S6\n",
        "for i in range(2):\n",
        "  print(\"Train sample #{}: {}\".format(i+1, ' '.join([vocab.itos[w] for w in ds_train[i]])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Evd0zLCAN1VR",
        "outputId": "d83f31f0-9de6-46b5-94bb-4e8492016868"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset is shaped : torch.Size([104335, 20])\n",
            "Validation dataset is shaped : torch.Size([10908, 20])\n",
            "Test dataset is shaped : torch.Size([12310, 20])\n",
            "Train sample #1: <eos> @ settlement heavy of , , lined the she <unk> of . interception the dried . , would his\n",
            "Train sample #2: = 1 was rains ireland and starting with hairy had found the <unk> to possibility heads other which receive gift\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCvcAVXOJebX"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 2  - Preparing the  Data - Separating to Inputs and Targets\n",
        "---\n",
        "* For a language modeling task, the model needs the following words as `Target`.\n",
        "    * For example, for the senetence \"I have a nice dog\", the model will be given \"I have a\" as input, and \"nice dog\" as the target.\n",
        "* Implement (complete) the function `get_batch(source, i, bptt)`: it generates the input and target sequence for the transformer model. It subdivides the source data into chunks of length `bptt`.\n",
        "    * For example, for `bptt=2` and at `i=0`, the output of `data, target = get_batch(train_data, i=0, bptt=2)`: `data` will be of shape (2, 20), where the batch size is 20 and `target` will be of length 40 (the target for each element is two words, but we flatten `target`).\n",
        "    * Print a sample from `data` and `target`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0801tyb6JebX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17979e95-630a-4181-a24b-11df654b6a07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data : tensor([[  12,   25,    5,    5, 1688,    0,   39,   59, 8785,    0,    6,   13,\n",
            "         3026,   43,   11,    6,    0,  349, 3134, 4538],\n",
            "        [   3,    6,   82, 1780,   21,    6, 2158,    4,    8,    8,   27, 1485,\n",
            "            0,  194,   96,  195, 3545,  101, 1150, 3486]], device='cuda:0')\n",
            "Target : tensor([   3,    6,   82, 1780,   21,    6, 2158,    4,    8,    8,   27, 1485,\n",
            "           0,  194,   96,  195, 3545,  101, 1150, 3486,    3,   25,   13,  885,\n",
            "           4, 6360,   15,  670,    0,   13,   26,   17,    5,  417,  894,   10,\n",
            "           5,    5, 2998,   27], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "def get_batch(source, i, bptt):\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i + seq_len]\n",
        "    target = source[i+1:i+1 + seq_len].view(-1)\n",
        "    return data, target\n",
        "\n",
        "d, t = get_batch(ds_train, 5, 2)\n",
        "print(\"Data : {}\".format(d))\n",
        "print(\"Target : {}\".format(t))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdVmIX_IJebX"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 3  - Define Hyperparameters and Initialize the Model\n",
        "---\n",
        "* Define the following hyperparameters (`[a, b]` means in the range between `a` and `b`):\n",
        "    * Embedding size: choose from `[200, 250]`\n",
        "    * Number of hidden units: choose from `[200, 250]`\n",
        "    * Number of layers: choose from `[2, 4]`\n",
        "    * Number of attention heads: choose from `[2, 4]`\n",
        "    * Dropout: choose from `[0.0, 0.3]`\n",
        "    * Loss criterion: `nn.CrossEntropyLoss()`\n",
        "    * Optimizer: choose from `[SGD, Adam]`\n",
        "    * Learning rate: choose from `[5e-3, 5.0]`\n",
        "    * Learning Scheduler: `torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)`\n",
        "* Intialize an instance of `TransformerModel` (given) and send it to `device`. Note that you need to give it the number of tokens to define the output of the decoder. You should use the number of tokens in the vocabulary. Print the number of tokens,  print **all** the chosen hyper-parameters and print the model (`print(model`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0d163qn8JebY"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "    \n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, ninp)\n",
        "        self.ninp = ninp\n",
        "        self.decoder = nn.Linear(ninp, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HI6I9YhJebY",
        "outputId": "1c590851-76a5-4886-abf9-86cba7152882"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding size: 240\n",
            "Number of hidden unit: 250\n",
            "Number of layer : 4\n",
            "Number of attention heads: 4\n",
            "Dropout rate: 0.1\n",
            "Learning rate: 1\n",
            "Number of tokens: 28785\n",
            "The  optimizer is SGD\n",
            "TransformerModel(\n",
            "  (pos_encoder): PositionalEncoding(\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (transformer_encoder): TransformerEncoder(\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=240, out_features=240, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=240, out_features=250, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=250, out_features=240, bias=True)\n",
            "        (norm1): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (1): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=240, out_features=240, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=240, out_features=250, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=250, out_features=240, bias=True)\n",
            "        (norm1): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (2): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=240, out_features=240, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=240, out_features=250, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=250, out_features=240, bias=True)\n",
            "        (norm1): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (3): TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (out_proj): NonDynamicallyQuantizableLinear(in_features=240, out_features=240, bias=True)\n",
            "        )\n",
            "        (linear1): Linear(in_features=240, out_features=250, bias=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "        (linear2): Linear(in_features=250, out_features=240, bias=True)\n",
            "        (norm1): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
            "        (norm2): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout1): Dropout(p=0.1, inplace=False)\n",
            "        (dropout2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (encoder): Embedding(28785, 240)\n",
            "  (decoder): Linear(in_features=240, out_features=28785, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "embd_sz = 240\n",
        "hidn_sz = 250\n",
        "layr_sz = 4\n",
        "atth_sz = 4\n",
        "dropout = 0.1\n",
        "lr = 1\n",
        "ntoken = len(vocab.stoi)\n",
        "print(\"Embedding size: {}\".format(embd_sz))\n",
        "print(\"Number of hidden unit: {}\".format(hidn_sz))\n",
        "print(\"Number of layer : {}\".format(layr_sz))\n",
        "print(\"Number of attention heads: {}\".format(atth_sz))\n",
        "print(\"Dropout rate: {}\".format(dropout))\n",
        "print(\"Learning rate: {}\".format(lr))\n",
        "print(\"Number of tokens: {}\".format(ntoken))\n",
        "print(\"The  optimizer is SGD\")\n",
        "\n",
        "model = TransformerModel(ntoken, embd_sz ,atth_sz, hidn_sz, layr_sz, dropout).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.90)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7OoAmA-Jeba"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 4  - Train and Evaluate the Language Model\n",
        "---\n",
        "* Fill in the missing line in the training code and train the model.\n",
        "* Use `bptt=35`.\n",
        "* Use the provided function to evaluate it on the validatation set (after each epoch) and on test test (after training is done). **Print and plot** the results (loss and perplexity).\n",
        "* If you see that the performance does not improve, go back to Task 3 and re-think you hyper-parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "s-piGDjMJeba"
      },
      "outputs": [],
      "source": [
        "def evaluate(eval_model, data_source):\n",
        "    eval_model.eval() # Turn on the evaluation mode\n",
        "    total_loss = 0.\n",
        "    ntokens = len(vocab.stoi)\n",
        "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, data_source.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(data_source, i, bptt)\n",
        "            if data.size(0) != bptt:\n",
        "                src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "            output = eval_model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += len(data) * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(data_source) - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "r2757Gh0Jebb"
      },
      "outputs": [],
      "source": [
        "def train(bptt):\n",
        "    model.train() # Turn on the train mode\n",
        "    total_loss = 0.\n",
        "    start_time = time.time()\n",
        "    ntokens =  len(vocab.stoi)\n",
        "    ret_loss = 0\n",
        "    src_mask = model.generate_square_subsequent_mask(bptt).to(device)\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "        data, targets = get_batch(train_data, i, bptt)\n",
        "        \n",
        "        if data.size(0) != bptt:\n",
        "            src_mask = model.generate_square_subsequent_mask(data.size(0)).to(device)\n",
        "            \n",
        "        output = model(data, src_mask)\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        log_interval = 700\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            cur_loss = cur_loss if cur_loss < 300 else 300\n",
        "            elapsed = time.time() - start_time\n",
        "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
        "                  'lr {:02.4f} | ms/batch {:5.2f} | '\n",
        "                  'loss {:5.2f} | ppl {:8.2f}'.format(\n",
        "                    epoch, batch, len(train_data) // bptt, scheduler.get_last_lr()[0],\n",
        "                    elapsed * 1000 / log_interval,\n",
        "                    cur_loss, math.exp(cur_loss)))\n",
        "            ret_loss += total_loss\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "    return (ret_loss + total_loss) /(len(list(range(0, train_data.size(0) - 1, bptt))))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = ds_train\n",
        "bptt = 35\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "  t = time.time()\n",
        "  train_loss = train(bptt)\n",
        "  epoch_time = time.time() - t\n",
        "  eval_loss = evaluate(model, ds_valid)\n",
        "  print('\\n| epoch {:3d} | validation          | '\n",
        "                  'lr {:02.4f} | s/epoch {:5.2f}  | '\n",
        "                  'loss {:5.2f}\\n'.format(\n",
        "                    epoch, scheduler.get_last_lr()[0],\n",
        "                    epoch_time,\n",
        "                   eval_loss))\n",
        "  scheduler.step()\n",
        "\n",
        "\n",
        "test_loss = evaluate(model, ds_test)\n",
        "print(\"Test loss after {} epochs is : {}\".format(epochs, test_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUs5ZZkIk-DI",
        "outputId": "a6609641-e9bd-4723-f341-94b50ec6f174"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   0 |   700/ 2981 batches | lr 1.0000 | ms/batch 14.47 | loss  6.83 | ppl   923.25\n",
            "| epoch   0 |  1400/ 2981 batches | lr 1.0000 | ms/batch 14.31 | loss  6.23 | ppl   510.15\n",
            "| epoch   0 |  2100/ 2981 batches | lr 1.0000 | ms/batch 14.34 | loss  6.05 | ppl   422.04\n",
            "| epoch   0 |  2800/ 2981 batches | lr 1.0000 | ms/batch 14.32 | loss  5.88 | ppl   356.63\n",
            "\n",
            "| epoch   0 | validation          | lr 1.0000 | s/epoch 42.81  | loss  5.69\n",
            "\n",
            "| epoch   1 |   700/ 2981 batches | lr 0.9000 | ms/batch 14.95 | loss  5.71 | ppl   302.54\n",
            "| epoch   1 |  1400/ 2981 batches | lr 0.9000 | ms/batch 14.29 | loss  5.61 | ppl   273.09\n",
            "| epoch   1 |  2100/ 2981 batches | lr 0.9000 | ms/batch 16.63 | loss  5.57 | ppl   263.68\n",
            "| epoch   1 |  2800/ 2981 batches | lr 0.9000 | ms/batch 14.29 | loss  5.48 | ppl   240.03\n",
            "\n",
            "| epoch   1 | validation          | lr 0.9000 | s/epoch 44.70  | loss  5.44\n",
            "\n",
            "| epoch   2 |   700/ 2981 batches | lr 0.8100 | ms/batch 14.34 | loss  5.40 | ppl   221.27\n",
            "| epoch   2 |  1400/ 2981 batches | lr 0.8100 | ms/batch 14.30 | loss  5.33 | ppl   206.69\n",
            "| epoch   2 |  2100/ 2981 batches | lr 0.8100 | ms/batch 14.29 | loss  5.32 | ppl   205.04\n",
            "| epoch   2 |  2800/ 2981 batches | lr 0.8100 | ms/batch 14.32 | loss  5.25 | ppl   190.21\n",
            "\n",
            "| epoch   2 | validation          | lr 0.8100 | s/epoch 42.99  | loss  5.31\n",
            "\n",
            "| epoch   3 |   700/ 2981 batches | lr 0.7290 | ms/batch 14.34 | loss  5.20 | ppl   180.65\n",
            "| epoch   3 |  1400/ 2981 batches | lr 0.7290 | ms/batch 14.32 | loss  5.14 | ppl   170.90\n",
            "| epoch   3 |  2100/ 2981 batches | lr 0.7290 | ms/batch 14.30 | loss  5.15 | ppl   172.40\n",
            "| epoch   3 |  2800/ 2981 batches | lr 0.7290 | ms/batch 14.32 | loss  5.08 | ppl   160.50\n",
            "\n",
            "| epoch   3 | validation          | lr 0.7290 | s/epoch 42.67  | loss  5.22\n",
            "\n",
            "| epoch   4 |   700/ 2981 batches | lr 0.6561 | ms/batch 14.34 | loss  5.05 | ppl   155.37\n",
            "| epoch   4 |  1400/ 2981 batches | lr 0.6561 | ms/batch 14.31 | loss  5.00 | ppl   148.61\n",
            "| epoch   4 |  2100/ 2981 batches | lr 0.6561 | ms/batch 14.32 | loss  5.02 | ppl   150.95\n",
            "| epoch   4 |  2800/ 2981 batches | lr 0.6561 | ms/batch 14.29 | loss  4.95 | ppl   140.93\n",
            "\n",
            "| epoch   4 | validation          | lr 0.6561 | s/epoch 42.66  | loss  5.17\n",
            "\n",
            "| epoch   5 |   700/ 2981 batches | lr 0.5905 | ms/batch 14.37 | loss  4.93 | ppl   138.20\n",
            "| epoch   5 |  1400/ 2981 batches | lr 0.5905 | ms/batch 14.32 | loss  4.89 | ppl   133.08\n",
            "| epoch   5 |  2100/ 2981 batches | lr 0.5905 | ms/batch 14.36 | loss  4.91 | ppl   135.89\n",
            "| epoch   5 |  2800/ 2981 batches | lr 0.5905 | ms/batch 14.29 | loss  4.84 | ppl   126.80\n",
            "\n",
            "| epoch   5 | validation          | lr 0.5905 | s/epoch 42.72  | loss  5.14\n",
            "\n",
            "| epoch   6 |   700/ 2981 batches | lr 0.5314 | ms/batch 14.36 | loss  4.83 | ppl   125.62\n",
            "| epoch   6 |  1400/ 2981 batches | lr 0.5314 | ms/batch 14.32 | loss  4.80 | ppl   121.48\n",
            "| epoch   6 |  2100/ 2981 batches | lr 0.5314 | ms/batch 14.33 | loss  4.82 | ppl   124.42\n",
            "| epoch   6 |  2800/ 2981 batches | lr 0.5314 | ms/batch 14.32 | loss  4.75 | ppl   116.06\n",
            "\n",
            "| epoch   6 | validation          | lr 0.5314 | s/epoch 42.70  | loss  5.11\n",
            "\n",
            "| epoch   7 |   700/ 2981 batches | lr 0.4783 | ms/batch 14.32 | loss  4.76 | ppl   116.19\n",
            "| epoch   7 |  1400/ 2981 batches | lr 0.4783 | ms/batch 14.33 | loss  4.72 | ppl   112.62\n",
            "| epoch   7 |  2100/ 2981 batches | lr 0.4783 | ms/batch 14.34 | loss  4.75 | ppl   115.62\n",
            "| epoch   7 |  2800/ 2981 batches | lr 0.4783 | ms/batch 14.29 | loss  4.68 | ppl   107.85\n",
            "\n",
            "| epoch   7 | validation          | lr 0.4783 | s/epoch 42.69  | loss  5.09\n",
            "\n",
            "| epoch   8 |   700/ 2981 batches | lr 0.4305 | ms/batch 14.30 | loss  4.69 | ppl   108.57\n",
            "| epoch   8 |  1400/ 2981 batches | lr 0.4305 | ms/batch 14.31 | loss  4.66 | ppl   105.42\n",
            "| epoch   8 |  2100/ 2981 batches | lr 0.4305 | ms/batch 14.31 | loss  4.69 | ppl   108.67\n",
            "| epoch   8 |  2800/ 2981 batches | lr 0.4305 | ms/batch 14.29 | loss  4.62 | ppl   101.25\n",
            "\n",
            "| epoch   8 | validation          | lr 0.4305 | s/epoch 42.62  | loss  5.08\n",
            "\n",
            "| epoch   9 |   700/ 2981 batches | lr 0.3874 | ms/batch 14.30 | loss  4.63 | ppl   102.49\n",
            "| epoch   9 |  1400/ 2981 batches | lr 0.3874 | ms/batch 14.34 | loss  4.60 | ppl    99.75\n",
            "| epoch   9 |  2100/ 2981 batches | lr 0.3874 | ms/batch 14.31 | loss  4.63 | ppl   102.91\n",
            "| epoch   9 |  2800/ 2981 batches | lr 0.3874 | ms/batch 14.30 | loss  4.57 | ppl    96.15\n",
            "\n",
            "| epoch   9 | validation          | lr 0.3874 | s/epoch 42.66  | loss  5.06\n",
            "\n",
            "| epoch  10 |   700/ 2981 batches | lr 0.3487 | ms/batch 14.36 | loss  4.58 | ppl    97.48\n",
            "| epoch  10 |  1400/ 2981 batches | lr 0.3487 | ms/batch 14.30 | loss  4.56 | ppl    95.27\n",
            "| epoch  10 |  2100/ 2981 batches | lr 0.3487 | ms/batch 14.37 | loss  4.59 | ppl    98.22\n",
            "| epoch  10 |  2800/ 2981 batches | lr 0.3487 | ms/batch 14.30 | loss  4.52 | ppl    91.54\n",
            "\n",
            "| epoch  10 | validation          | lr 0.3487 | s/epoch 42.71  | loss  5.05\n",
            "\n",
            "| epoch  11 |   700/ 2981 batches | lr 0.3138 | ms/batch 14.34 | loss  4.54 | ppl    93.41\n",
            "| epoch  11 |  1400/ 2981 batches | lr 0.3138 | ms/batch 14.32 | loss  4.51 | ppl    91.34\n",
            "| epoch  11 |  2100/ 2981 batches | lr 0.3138 | ms/batch 14.29 | loss  4.55 | ppl    94.42\n",
            "| epoch  11 |  2800/ 2981 batches | lr 0.3138 | ms/batch 14.33 | loss  4.48 | ppl    88.00\n",
            "\n",
            "| epoch  11 | validation          | lr 0.3138 | s/epoch 42.68  | loss  5.04\n",
            "\n",
            "| epoch  12 |   700/ 2981 batches | lr 0.2824 | ms/batch 14.34 | loss  4.50 | ppl    90.00\n",
            "| epoch  12 |  1400/ 2981 batches | lr 0.2824 | ms/batch 14.30 | loss  4.48 | ppl    88.15\n",
            "| epoch  12 |  2100/ 2981 batches | lr 0.2824 | ms/batch 14.30 | loss  4.51 | ppl    90.94\n",
            "| epoch  12 |  2800/ 2981 batches | lr 0.2824 | ms/batch 14.34 | loss  4.44 | ppl    84.88\n",
            "\n",
            "| epoch  12 | validation          | lr 0.2824 | s/epoch 42.69  | loss  5.04\n",
            "\n",
            "| epoch  13 |   700/ 2981 batches | lr 0.2542 | ms/batch 14.36 | loss  4.47 | ppl    87.09\n",
            "| epoch  13 |  1400/ 2981 batches | lr 0.2542 | ms/batch 14.30 | loss  4.45 | ppl    85.34\n",
            "| epoch  13 |  2100/ 2981 batches | lr 0.2542 | ms/batch 14.29 | loss  4.48 | ppl    88.43\n",
            "| epoch  13 |  2800/ 2981 batches | lr 0.2542 | ms/batch 14.32 | loss  4.41 | ppl    82.28\n",
            "\n",
            "| epoch  13 | validation          | lr 0.2542 | s/epoch 42.68  | loss  5.03\n",
            "\n",
            "| epoch  14 |   700/ 2981 batches | lr 0.2288 | ms/batch 14.34 | loss  4.44 | ppl    84.58\n",
            "| epoch  14 |  1400/ 2981 batches | lr 0.2288 | ms/batch 14.30 | loss  4.42 | ppl    83.08\n",
            "| epoch  14 |  2100/ 2981 batches | lr 0.2288 | ms/batch 14.32 | loss  4.45 | ppl    85.95\n",
            "| epoch  14 |  2800/ 2981 batches | lr 0.2288 | ms/batch 14.30 | loss  4.38 | ppl    80.03\n",
            "\n",
            "| epoch  14 | validation          | lr 0.2288 | s/epoch 42.66  | loss  5.03\n",
            "\n",
            "| epoch  15 |   700/ 2981 batches | lr 0.2059 | ms/batch 14.35 | loss  4.41 | ppl    82.52\n",
            "| epoch  15 |  1400/ 2981 batches | lr 0.2059 | ms/batch 14.32 | loss  4.39 | ppl    81.04\n",
            "| epoch  15 |  2100/ 2981 batches | lr 0.2059 | ms/batch 14.31 | loss  4.43 | ppl    83.79\n",
            "| epoch  15 |  2800/ 2981 batches | lr 0.2059 | ms/batch 14.29 | loss  4.36 | ppl    78.17\n",
            "\n",
            "| epoch  15 | validation          | lr 0.2059 | s/epoch 42.67  | loss  5.02\n",
            "\n",
            "| epoch  16 |   700/ 2981 batches | lr 0.1853 | ms/batch 14.37 | loss  4.39 | ppl    80.73\n",
            "| epoch  16 |  1400/ 2981 batches | lr 0.1853 | ms/batch 14.32 | loss  4.37 | ppl    79.36\n",
            "| epoch  16 |  2100/ 2981 batches | lr 0.1853 | ms/batch 14.30 | loss  4.41 | ppl    82.08\n",
            "| epoch  16 |  2800/ 2981 batches | lr 0.1853 | ms/batch 14.33 | loss  4.34 | ppl    76.58\n",
            "\n",
            "| epoch  16 | validation          | lr 0.1853 | s/epoch 42.70  | loss  5.02\n",
            "\n",
            "| epoch  17 |   700/ 2981 batches | lr 0.1668 | ms/batch 14.31 | loss  4.37 | ppl    79.35\n",
            "| epoch  17 |  1400/ 2981 batches | lr 0.1668 | ms/batch 14.34 | loss  4.35 | ppl    77.83\n",
            "| epoch  17 |  2100/ 2981 batches | lr 0.1668 | ms/batch 14.33 | loss  4.39 | ppl    80.61\n",
            "| epoch  17 |  2800/ 2981 batches | lr 0.1668 | ms/batch 14.30 | loss  4.32 | ppl    75.17\n",
            "\n",
            "| epoch  17 | validation          | lr 0.1668 | s/epoch 42.67  | loss  5.01\n",
            "\n",
            "| epoch  18 |   700/ 2981 batches | lr 0.1501 | ms/batch 14.33 | loss  4.36 | ppl    78.10\n",
            "| epoch  18 |  1400/ 2981 batches | lr 0.1501 | ms/batch 14.34 | loss  4.34 | ppl    76.60\n",
            "| epoch  18 |  2100/ 2981 batches | lr 0.1501 | ms/batch 14.29 | loss  4.37 | ppl    79.29\n",
            "| epoch  18 |  2800/ 2981 batches | lr 0.1501 | ms/batch 14.33 | loss  4.30 | ppl    73.95\n",
            "\n",
            "| epoch  18 | validation          | lr 0.1501 | s/epoch 42.69  | loss  5.01\n",
            "\n",
            "| epoch  19 |   700/ 2981 batches | lr 0.1351 | ms/batch 14.33 | loss  4.34 | ppl    76.90\n",
            "| epoch  19 |  1400/ 2981 batches | lr 0.1351 | ms/batch 14.25 | loss  4.32 | ppl    75.52\n",
            "| epoch  19 |  2100/ 2981 batches | lr 0.1351 | ms/batch 14.33 | loss  4.36 | ppl    78.21\n",
            "| epoch  19 |  2800/ 2981 batches | lr 0.1351 | ms/batch 14.31 | loss  4.29 | ppl    72.86\n",
            "\n",
            "| epoch  19 | validation          | lr 0.1351 | s/epoch 42.65  | loss  5.01\n",
            "\n",
            "Test loss after 20 epochs is : 4.926882636644905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV6M01oyJebb"
      },
      "source": [
        "### <img src=\"https://img.icons8.com/color/48/000000/code.png\" style=\"height:50px;display:inline\"> Task 5  - Generate Sentences\n",
        "---\n",
        "Use the following function to generate 3 sentences of length 20, and print them. Do they make sense? (you can compare generated sentences over epochs, to see if some logic is gained during training)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "b6kvCr6bJebb"
      },
      "outputs": [],
      "source": [
        "def generate(model, vocab, nwords=100, temp=1.0):\n",
        "    model.eval()\n",
        "    ntokens = len(vocab.stoi)\n",
        "    model_input = torch.randint(ntokens, (1, 1), dtype=torch.long).to(device)\n",
        "    words = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(nwords):\n",
        "            output = model(model_input, None)\n",
        "            word_weights = output[-1].squeeze().div(temp).exp().cpu()\n",
        "            word_idx = torch.multinomial(word_weights, 1)[0]\n",
        "            word_tensor = torch.Tensor([[word_idx]]).long().to(device)\n",
        "            model_input = torch.cat([model_input, word_tensor], 0)\n",
        "            word = vocab.itos[word_idx]\n",
        "            words.append(word)\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QZq0-81Jebc",
        "outputId": "71c15f58-a726-49e6-b973-57dc2efb6eb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated sentence #0 : . <eos> marlborough brought the division i blackley returned to ended by year with the first division in 50 years\n",
            "Generated sentence #1 : @-@ 13b — white , and rarely even the decay . the 337 <eos> it appears as a brutal evolution\n",
            "Generated sentence #2 : lauren . he was in <unk> <unk> , the latter writer william huey of the book that of king john\n"
          ]
        }
      ],
      "source": [
        "for i in range(3):\n",
        "  print(\"Generated sentence #{} : {}\".format(i,\" \".join(generate(model, vocab, 20))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_P5T9pUUJebc"
      },
      "source": [
        "## <img src=\"https://img.icons8.com/dusk/64/000000/prize.png\" style=\"height:50px;display:inline\"> Credits\n",
        "---\n",
        "* Icons made by <a href=\"https://www.flaticon.com/authors/becris\" title=\"Becris\">Becris</a> from <a href=\"https://www.flaticon.com/\" title=\"Flaticon\">www.flaticon.com</a>\n",
        "* Icons from <a href=\"https://icons8.com/\">Icons8.com</a> - https://icons8.com\n",
        "* Datasets from <a href=\"https://www.kaggle.com/\">Kaggle</a> - https://www.kaggle.com/"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "ee046211_hw3_seq_tasks_students.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}